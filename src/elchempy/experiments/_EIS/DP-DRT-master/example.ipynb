{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3) Take vectors and matrices from numpy to torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Prior Distribution of Relaxation Times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In this tutorial we will reproduce Figure 2 in\n",
    "## Liu, J., & Ciucci, F. (2020). The Deep-Prior Distribution of Relaxation Times. Journal of The Electrochemical Society, 167(2), 026506\n",
    "## https://iopscience.iop.org/article/10.1149/1945-7111/ab631a/meta\n",
    "\n",
    "The DP-DRT method is our next newly developed deep learning based approach to obtain the DRT from the EIS data. The DP-DRT is trained on a single electrochemical impedance spectrum. A single random input is given to the nerural network underlying the DP-DRT. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import random as rnd\n",
    "from math import cos, pi, sin\n",
    "\n",
    "import compute_DRT\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# check the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "if device.type == \"cuda\":\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print(\"Memory Usage:\")\n",
    "    print(\"Allocated:\", round(torch.cuda.memory_allocated(0) / 1024 ** 2, 1), \"MB\")\n",
    "    print(\"Cached:   \", round(torch.cuda.memory_cached(0) / 1024 ** 2, 1), \"MB\")\n",
    "\n",
    "# we will assume you have a cpu\n",
    "# if you want to use a GPU, you will need to use cuda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Problem setup\n",
    "### 1.1) Generate a single stochastic experiment \n",
    "### note: the exact circuit is a ZARC\n",
    "\n",
    "The impedance of a ZARC can be written as\n",
    "$$\n",
    "Z^{\\rm exact}(f) = R_\\infty + \\displaystyle \\frac{1}{\\displaystyle \\frac{1}{R_{\\rm ct}}+C \\left(i 2\\pi f\\right)^\\phi}\n",
    "$$\n",
    "\n",
    "where $\\displaystyle C = \\frac{\\tau_0^\\phi}{R_{\\rm ct}}$.\n",
    "\n",
    "The analytical DRT can be computed analytically as\n",
    "\n",
    "$$\n",
    "\\gamma(\\log \\tau) =  \\displaystyle \\frac{\\displaystyle R_{\\rm ct}}{\\displaystyle 2\\pi} \\displaystyle \\frac{\\displaystyle \\sin\\left((1-\\phi)\\pi\\right)}{\\displaystyle \\cosh(\\phi \\log(\\tau/\\tau_0))-\\cos(\\pi(1-\\phi))}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the seed for the random number generators\n",
    "rng = rnd.seed(214975)\n",
    "rng_np = np.random.seed(213912)\n",
    "torch.manual_seed(213912)\n",
    "\n",
    "# define frequency range, from 1E-4 to 1E4 with 10 ppd\n",
    "N_freqs = 81\n",
    "freq_vec = np.logspace(-4.0, 4.0, num=N_freqs, endpoint=True)\n",
    "tau_vec = 1.0 / freq_vec\n",
    "\n",
    "# define parameters for ZARC model and calculate the impedance and gamma following the above equations\n",
    "R_inf = 10\n",
    "R_ct = 50\n",
    "phi = 0.8\n",
    "tau_0 = 1\n",
    "C = tau_0 ** phi / R_ct\n",
    "\n",
    "# exact Z and gamma\n",
    "Z = R_inf + 1.0 / (1.0 / R_ct + C * (1j * 2.0 * pi * freq_vec) ** phi)\n",
    "gamma_exact = (\n",
    "    (R_ct)\n",
    "    / (2.0 * pi)\n",
    "    * sin((1.0 - phi) * pi)\n",
    "    / (np.cosh(phi * np.log(tau_vec / tau_0)) - cos((1.0 - phi) * pi))\n",
    ")\n",
    "\n",
    "# adding noise to the impedance data\n",
    "sigma_n_exp = 0.1\n",
    "Z_exp = Z + sigma_n_exp * (\n",
    "    np.random.normal(0, 1, N_freqs) + 1j * np.random.normal(0, 1, N_freqs)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2) Build $\\mathbf A_{\\rm re}$ and $\\mathbf A_{\\rm im}$ matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the matrices that calculate the impedace from DRT, i.e., Z_re = A_re * gamma, Z_im = A_im * gamma\n",
    "A_re = compute_DRT.A_re(freq_vec)\n",
    "A_im = compute_DRT.A_im(freq_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# size of the arbitrary zeta input\n",
    "N_zeta = 1\n",
    "\n",
    "# define the neural network\n",
    "# N is batch size, D_in is input dimension, H is hidden dimension, D_out is output dimension.\n",
    "N = 1\n",
    "D_in = N_zeta\n",
    "H = max(N_freqs, 10 * N_zeta)\n",
    "# the output also includes the R_inf, so it has dimension N_freq+1\n",
    "# note that\n",
    "# 1) there is no inductance (in this specific example - the DP-DRT can include inductive features, see article)\n",
    "# 2) R_inf is stored as the last item in the NN output\n",
    "\n",
    "D_out = N_freqs + 1\n",
    "\n",
    "# Construct the neural network structure\n",
    "class vanilla_model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(vanilla_model, self).__init__()\n",
    "        self.fct_1 = torch.nn.Linear(D_in, H)\n",
    "        self.fct_2 = torch.nn.Linear(H, H)\n",
    "        self.fct_3 = torch.nn.Linear(H, H)\n",
    "        self.fct_4 = torch.nn.Linear(H, D_out)\n",
    "\n",
    "        # initialize the weight parameters\n",
    "        torch.nn.init.zeros_(self.fct_1.weight)\n",
    "        torch.nn.init.zeros_(self.fct_2.weight)\n",
    "        torch.nn.init.zeros_(self.fct_3.weight)\n",
    "        torch.nn.init.zeros_(self.fct_4.weight)\n",
    "\n",
    "    # forward\n",
    "    def forward(self, zeta):\n",
    "        h = F.elu(self.fct_1(zeta))\n",
    "        h = F.elu(self.fct_2(h))\n",
    "        h = F.elu(self.fct_3(h))\n",
    "        gamma_pred = F.softplus(self.fct_4(h), beta=5)\n",
    "\n",
    "        return gamma_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform impedance variables to tensors\n",
    "Z_exp_re_torch = (\n",
    "    torch.from_numpy(np.real(Z_exp)).type(torch.FloatTensor).reshape(1, N_freqs)\n",
    ")\n",
    "Z_exp_im_torch = (\n",
    "    torch.from_numpy(np.imag(Z_exp)).type(torch.FloatTensor).reshape(1, N_freqs)\n",
    ")\n",
    "# tranform gamma\n",
    "gamma_exact_torch = torch.from_numpy(gamma_exact).type(torch.FloatTensor)\n",
    "\n",
    "# transform these matrices into tensors\n",
    "A_re_torch = torch.from_numpy(A_re.T).type(torch.FloatTensor)\n",
    "A_im_torch = torch.from_numpy(A_im.T).type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Setup DP-DRT model\n",
    "### 2.1) Deep network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  2.2) Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(output, Z_exp_re_torch, Z_exp_im_torch, A_re_torch, A_im_torch):\n",
    "\n",
    "    # we assume no inductance and the R_inf is stored as the last item in the NN output\n",
    "\n",
    "    MSE_re = torch.sum(\n",
    "        (output[:, -1] + torch.mm(output[:, 0:-1], A_re_torch) - Z_exp_re_torch) ** 2\n",
    "    )\n",
    "    MSE_im = torch.sum((torch.mm(output[:, 0:-1], A_im_torch) - Z_exp_im_torch) ** 2)\n",
    "    MSE = MSE_re + MSE_im\n",
    "\n",
    "    return MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = vanilla_model()\n",
    "\n",
    "# initialize following variables\n",
    "zeta = torch.randn(N, N_zeta)\n",
    "loss_vec = np.array([])\n",
    "distance_vec = np.array([])\n",
    "lambda_vec = np.array([])\n",
    "\n",
    "# optimize the neural network\n",
    "learning_rate = 1e-5\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# max iterations\n",
    "max_iters = 100001\n",
    "gamma_NN_store = torch.zeros((max_iters, N_freqs))\n",
    "R_inf_NN_store = torch.zeros((max_iters, 1))\n",
    "\n",
    "for t in range(max_iters):\n",
    "    # Forward pass: compute predicted y by passing x to the model.\n",
    "    gamma = model(zeta)\n",
    "\n",
    "    # Compute the loss\n",
    "    loss = loss_fn(gamma, Z_exp_re_torch, Z_exp_im_torch, A_re_torch, A_im_torch)\n",
    "    # save it\n",
    "    loss_vec = np.append(loss_vec, loss.item())\n",
    "\n",
    "    # store gamma\n",
    "    gamma_NN = gamma[:, 0:-1].detach().reshape(-1)\n",
    "    gamma_NN_store[t, :] = gamma_NN\n",
    "\n",
    "    # store R_inf\n",
    "    R_inf_NN_store[t, :] = gamma[:, -1].detach().reshape(-1)\n",
    "\n",
    "    # Compute the distance\n",
    "    distance = math.sqrt(torch.sum((gamma_NN - gamma_exact_torch) ** 2).item())\n",
    "    # save it\n",
    "    distance_vec = np.append(distance_vec, distance)\n",
    "\n",
    "    # and print it\n",
    "    if not t % 100:\n",
    "        print(\"iter=\", t, \"; loss=\", loss.item(), \"; distance=\", distance)\n",
    "\n",
    "    # zero all gradients (purge any cache)\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # compute the gradient of the loss with respect to model parameters\n",
    "    loss.backward()\n",
    "\n",
    "    # Update the optimizer\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Analyze results\n",
    "### 4.1) Find early stopping value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_opt = np.argmin(distance_vec)\n",
    "index_early_stop = np.flatnonzero(np.abs(np.diff(loss_vec)) < 1e-8)\n",
    "\n",
    "gamma_DIP_torch_opt = gamma_NN_store[index_opt, :]\n",
    "R_inf_DIP_torch_opt = R_inf_NN_store[index_opt, :]\n",
    "\n",
    "gamma_DIP_opt = gamma_DIP_torch_opt.detach().numpy()\n",
    "R_DIP_opt = R_inf_DIP_torch_opt.detach().numpy()\n",
    "\n",
    "if len(index_early_stop):\n",
    "    gamma_DIP_torch_early_stop = gamma_NN_store[index_early_stop[0], :]\n",
    "    gamma_DIP = gamma_DIP_torch_early_stop.detach().numpy()\n",
    "    R_DIP = R_inf_NN_store[index_early_stop[0], :]\n",
    "    R_DIP = R_DIP.detach().numpy()\n",
    "else:\n",
    "    gamma_DIP = gamma_DIP_opt\n",
    "    R_DIP = R_DIP_opt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2) Plot the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.semilogy(loss_vec, linewidth=4, color=\"black\")\n",
    "plt.semilogy(\n",
    "    np.array([index_early_stop[0], index_early_stop[0]]),\n",
    "    np.array([1e-3, 1e7]),\n",
    "    \":\",\n",
    "    linewidth=3,\n",
    "    color=\"red\",\n",
    ")\n",
    "plt.semilogy(\n",
    "    np.array([index_opt, index_opt]),\n",
    "    np.array([1e-3, 1e7]),\n",
    "    \":\",\n",
    "    linewidth=3,\n",
    "    color=\"blue\",\n",
    ")\n",
    "plt.text(\n",
    "    30000,\n",
    "    1e2,\n",
    "    r\"early stop\",\n",
    "    {\n",
    "        \"color\": \"red\",\n",
    "        \"fontsize\": 20,\n",
    "        \"ha\": \"center\",\n",
    "        \"va\": \"center\",\n",
    "        \"rotation\": 90,\n",
    "        \"bbox\": dict(boxstyle=\"round\", fc=\"white\", ec=\"red\", pad=0.2),\n",
    "    },\n",
    ")\n",
    "plt.text(\n",
    "    0.93e5,\n",
    "    1e2,\n",
    "    r\"optimal\",\n",
    "    {\n",
    "        \"color\": \"blue\",\n",
    "        \"fontsize\": 20,\n",
    "        \"ha\": \"center\",\n",
    "        \"va\": \"center\",\n",
    "        \"rotation\": 90,\n",
    "        \"bbox\": dict(boxstyle=\"round\", fc=\"white\", ec=\"blue\", pad=0.2),\n",
    "    },\n",
    ")\n",
    "plt.rc(\"text\", usetex=False)\n",
    "plt.rc(\"font\", family=\"serif\", size=15)\n",
    "plt.rc(\"xtick\", labelsize=15)\n",
    "plt.rc(\"ytick\", labelsize=15)\n",
    "plt.xlabel(r\"iter\", fontsize=20)\n",
    "plt.ylabel(r\"loss\", fontsize=20)\n",
    "plt.axis([0, 1.01e5, 0.9e-2, 1.1e6])\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(5, 4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3) Plot the error curve vs. iteration\n",
    "The error is defined as the distance between predicted DRT and exact DRT, i.e.,$ \\rm error = ||\\mathbf \\gamma_{\\rm exact} - \\mathbf \\gamma_{\\rm DP-DRT}||$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.semilogy(distance_vec, linewidth=4, color=\"black\")\n",
    "plt.semilogy(\n",
    "    np.array([index_early_stop[0], index_early_stop[0]]),\n",
    "    np.array([1e-3, 1e7]),\n",
    "    \":\",\n",
    "    linewidth=4,\n",
    "    color=\"red\",\n",
    ")\n",
    "plt.semilogy(\n",
    "    np.array([index_opt, index_opt]),\n",
    "    np.array([1e-3, 1e7]),\n",
    "    \":\",\n",
    "    linewidth=4,\n",
    "    color=\"blue\",\n",
    ")\n",
    "plt.text(\n",
    "    30000,\n",
    "    2e1,\n",
    "    r\"early stop\",\n",
    "    {\n",
    "        \"color\": \"red\",\n",
    "        \"fontsize\": 20,\n",
    "        \"ha\": \"center\",\n",
    "        \"va\": \"center\",\n",
    "        \"rotation\": 90,\n",
    "        \"bbox\": dict(boxstyle=\"round\", fc=\"white\", ec=\"red\", pad=0.2),\n",
    "    },\n",
    ")\n",
    "plt.text(\n",
    "    0.93e5,\n",
    "    2e1,\n",
    "    r\"optimal\",\n",
    "    {\n",
    "        \"color\": \"blue\",\n",
    "        \"fontsize\": 20,\n",
    "        \"ha\": \"center\",\n",
    "        \"va\": \"center\",\n",
    "        \"rotation\": 90,\n",
    "        \"bbox\": dict(boxstyle=\"round\", fc=\"white\", ec=\"blue\", pad=0.2),\n",
    "    },\n",
    ")\n",
    "plt.rc(\"text\", usetex=False)\n",
    "plt.rc(\"font\", family=\"serif\", size=15)\n",
    "plt.rc(\"xtick\", labelsize=15)\n",
    "plt.rc(\"ytick\", labelsize=15)\n",
    "plt.xlabel(r\"iter\", fontsize=20)\n",
    "plt.ylabel(r\"error\", fontsize=20)\n",
    "plt.axis([0, 1.01e5, 0.9e0, 1.1e2])\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(5, 4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4) Plot the impedance\n",
    "We compare the DP-DRT EIS spectrum against the one from the stochastic experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_DIP = R_DIP + np.matmul(A_re, gamma_DIP) + 1j * np.matmul(A_im, gamma_DIP)\n",
    "\n",
    "plt.plot(\n",
    "    np.real(Z_exp),\n",
    "    -np.imag(Z_exp),\n",
    "    \"o\",\n",
    "    markersize=10,\n",
    "    color=\"black\",\n",
    "    label=\"synth exp\",\n",
    ")\n",
    "plt.plot(np.real(Z_DIP), -np.imag(Z_DIP), linewidth=4, color=\"red\", label=\"DP-DRT\")\n",
    "plt.rc(\"text\", usetex=False)\n",
    "plt.rc(\"font\", family=\"serif\", size=20)\n",
    "plt.annotate(\n",
    "    r\"$10^{-2}$\",\n",
    "    xy=(np.real(Z_exp[20]), -np.imag(Z_exp[20])),\n",
    "    xytext=(np.real(Z_exp[20]) - 2, 10 - np.imag(Z_exp[20])),\n",
    "    arrowprops=dict(arrowstyle=\"-\", connectionstyle=\"arc\"),\n",
    ")\n",
    "plt.annotate(\n",
    "    r\"$10^{-1}$\",\n",
    "    xy=(np.real(Z_exp[30]), -np.imag(Z_exp[30])),\n",
    "    xytext=(np.real(Z_exp[30]) - 2, 6 - np.imag(Z_exp[30])),\n",
    "    arrowprops=dict(arrowstyle=\"-\", connectionstyle=\"arc\"),\n",
    ")\n",
    "plt.annotate(\n",
    "    r\"$1$\",\n",
    "    xy=(np.real(Z_exp[40]), -np.imag(Z_exp[40])),\n",
    "    xytext=(np.real(Z_exp[40]), 10 - np.imag(Z_exp[40])),\n",
    "    arrowprops=dict(arrowstyle=\"-\", connectionstyle=\"arc\"),\n",
    ")\n",
    "plt.annotate(\n",
    "    r\"$10$\",\n",
    "    xy=(np.real(Z_exp[50]), -np.imag(Z_exp[50])),\n",
    "    xytext=(np.real(Z_exp[50]) - 1, 10 - np.imag(Z_exp[50])),\n",
    "    arrowprops=dict(arrowstyle=\"-\", connectionstyle=\"arc\"),\n",
    ")\n",
    "plt.rc(\"xtick\", labelsize=15)\n",
    "plt.rc(\"ytick\", labelsize=15)\n",
    "plt.legend(frameon=False, fontsize=15)\n",
    "plt.xlim(10, 65)\n",
    "plt.ylim(0, 55)\n",
    "plt.xticks(range(0, 70, 10))\n",
    "plt.yticks(range(0, 60, 10))\n",
    "plt.gca().set_aspect(\"equal\", adjustable=\"box\")\n",
    "plt.xlabel(r\"$Z_{\\rm re}/\\Omega$\", fontsize=20)\n",
    "plt.ylabel(r\"$-Z_{\\rm im}/\\Omega$\", fontsize=20)\n",
    "fig = plt.gcf()\n",
    "size = fig.get_size_inches()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5) Plot the DRT\n",
    "We compare the $\\gamma$ from the DP-DRT model against the exact one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.semilogx(tau_vec, gamma_exact, linewidth=4, color=\"black\", label=\"exact\")\n",
    "plt.semilogx(tau_vec, gamma_DIP, linewidth=4, color=\"red\", label=\"early stop\")\n",
    "plt.semilogx(\n",
    "    tau_vec, gamma_DIP_opt, linestyle=\"None\", marker=\"o\", color=\"blue\", label=\"optimal\"\n",
    ")\n",
    "plt.rc(\"text\", usetex=False)\n",
    "plt.rc(\"font\", family=\"serif\", size=15)\n",
    "plt.rc(\"xtick\", labelsize=15)\n",
    "plt.rc(\"ytick\", labelsize=15)\n",
    "plt.axis([1e-4, 1e4, -0.4, 25])\n",
    "plt.legend(frameon=False, fontsize=15)\n",
    "plt.xlabel(r\"$\\tau/{\\rm s}$\", fontsize=20)\n",
    "plt.ylabel(r\"$\\gamma/\\Omega$\", fontsize=20)\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(5, 4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6) Ancillary data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"total number parameters = \", compute_DRT.count_parameters(model))\n",
    "print(\"distance_early_stop = \", distance_vec[index_early_stop[0]])\n",
    "print(\"distance_opt= \", distance_vec[index_opt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
